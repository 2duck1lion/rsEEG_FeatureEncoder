{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a916e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import schedules\n",
    "import os\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   #if like me you do not have a lot of memory in your GPU\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\" #then these two lines force keras to use your CPU\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import librosa\n",
    "import os as os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from matplotlib import cm, colors, colorbar\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "rdg = RidgeClassifier(alpha=0.5)\n",
    "#mlp=MLPClassifier(random_state=1,max_iter=300,activation='relu',solver='sgd',learning_rate='constant',learning_rate_init=0.0001)\n",
    "mlp=MLPClassifier(random_state=1,max_iter=300,activation='relu')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lgr=LogisticRegression(random_state=1,max_iter=500)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT = DecisionTreeClassifier(random_state=0,max_depth=10)\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adb = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc= GradientBoostingClassifier(n_estimators=100, random_state=1)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "#SGD=SGDClassifier(loss= 'log',random_state=1,max_iter=100,early_stopping=True,learning_rate='optimal',validation_fraction=0.2)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = StandardScaler()\n",
    "mmscaler= MinMaxScaler()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "from sklearn.svm import SVC\n",
    "clf_svm=SVC(kernel='rbf')\n",
    "linear_svm=SVC(kernel='linear')\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "from scipy.spatial import ConvexHull, convex_hull_plot_2d\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats.mstats import mquantiles\n",
    "from scipy.stats import skew\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "pca = PCA(n_components=2, svd_solver='full')\n",
    "import random\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42e02b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_eeg(data):\n",
    "    with open(data) as f:\n",
    "        raw = []\n",
    "        for line in f:\n",
    "            line = line.split() # to deal with blank \n",
    "            if line:            # lines (ie skip them)\n",
    "                line = [int(float(i)) for i in line]\n",
    "                raw.append(line)\n",
    "    df = pd.DataFrame (raw,columns=['Channel_1','Channel_2','Channel_3','Channel_4','Channel_5','Channel_6','Channel_7','Channel_8',\n",
    "                            'Channel_9','Channel_10','Channel_11','Channel_12','Channel_13','Channel_14','Channel_15'\n",
    "                             ,'Channel_16','Channel_17','Channel_18','Channel_19'])\n",
    "    return df\n",
    "\n",
    "from scipy.signal import butter, lfilter\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=6):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def noise_filter(df):\n",
    "    filt_data=pd.Series()\n",
    "    for i in range(0, df.shape[1]):\n",
    "        signal = df.iloc[:,i].values\n",
    "        data=butter_bandpass_filter(signal,0.1,45,128,3)\n",
    "        \n",
    "        filt_data=pd.concat([filt_data,pd.Series(data)],axis=1)\n",
    "    filt_data=filt_data.iloc[:,1:]\n",
    "    filt_data.columns = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12',\n",
    "       '13', '14', '15', '16', '17', '18', '19']\n",
    "    return filt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fa63b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tps=34944-5*128 # cut all EEG of all subjects into equal length = 34944-5*128=34304 time points\n",
    "number_of_epochs=26 # segment each subject's EEG into 26 epochs\n",
    "number_of_tps=1280 # each epoch include 1280 time points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7980b75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/jupy/Raw_data/Time_0/Obese\")\n",
    "ob_0=os.listdir(os.getcwd())\n",
    "ob_0.remove('.ipynb_checkpoints')\n",
    "#ob_0.remove('New')\n",
    "\n",
    "eeg_ob_0=np.zeros([len(ob_0),total_tps,19])\n",
    "for i in range(0,len(ob_0)):\n",
    "    eeg_ob_0[i,:,:]=(read_eeg(ob_0[i]).values)[0:total_tps,:]\n",
    "\n",
    "os.chdir(\"/home/jupy/Raw_data/Time_0/Lean\")\n",
    "l_0=os.listdir(os.getcwd())\n",
    "l_0.remove('.ipynb_checkpoints')\n",
    "#l_0.remove('New')\n",
    "\n",
    "eeg_l_0=np.zeros([len(l_0),total_tps,19])\n",
    "for i in range(0,len(l_0)):\n",
    "    eeg_l_0[i,:,:]=(read_eeg(l_0[i]).values)[0:total_tps,:]\n",
    "    \n",
    "X_0=np.vstack([eeg_ob_0,eeg_l_0])\n",
    "print ('eeg_ob_0',eeg_ob_0.shape)\n",
    "print ('eeg_l_0',eeg_l_0.shape)\n",
    "print('X_0',X_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6fa63e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y=[0]*30+[1]*30\n",
    "\n",
    "X_0_clean=np.zeros([60, 34304, 19])\n",
    "for i in range(0,X_0.shape[0]):\n",
    "    X_0_clean[i,:,:]=noise_filter(pd.DataFrame(X_0[i,:,:]))\n",
    "X_0_clean=X_0_clean[:,0:int(number_of_epochs*number_of_tps),:]\n",
    "\n",
    "X2_0=np.zeros([number_of_epochs*X_0_clean.shape[0],int(number_of_tps),19])\n",
    "for chan in range(0,19):\n",
    "    X1=np.zeros([number_of_epochs*X_0_clean.shape[0],int(number_of_tps)])\n",
    "    for subj in range(0,X_0_clean.shape[0]):\n",
    "        X1[subj*number_of_epochs:(subj+1)*number_of_epochs,:]=X_0_clean[subj,0:int(number_of_epochs*number_of_tps),chan].reshape(int(number_of_epochs),int(number_of_tps))\n",
    "    X2_0[:,:,chan]=X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4851e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_0=np.zeros([X2_0.shape[0],19,number_of_tps])\n",
    "for i in range(0,X2_0.shape[0]):\n",
    "    XX_0[i,:,:]=X2_0[i,:,:].transpose()\n",
    "print(XX_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3abc42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y2=[]\n",
    "for n in y:\n",
    "    Y2=Y2+[n]*number_of_epochs\n",
    "len(Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695ca7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "del eeg_l_0\n",
    "del eeg_ob_0\n",
    "del X_0\n",
    "del X_0_clean\n",
    "del X2_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3148fa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_short=[1,1,1,0,0,0]\n",
    "\n",
    "def subj_class_prob(result):\n",
    "    pred=[]\n",
    "    for i in range(0,6):\n",
    "        #print(np.where(np.array(result[i*number_of_epochs:(i+1)*number_of_epochs])==1)[0].shape[0]/number_of_epochs)\n",
    "        print(sum(predicted[i*number_of_epochs:(i+1)*number_of_epochs])[0], sum(predicted[i*number_of_epochs:(i+1)*number_of_epochs])[1])\n",
    "        if sum(predicted[i*number_of_epochs:(i+1)*number_of_epochs])[0]>sum(predicted[i*number_of_epochs:(i+1)*number_of_epochs])[1]:\n",
    "            pred.append(0)\n",
    "        else:\n",
    "            pred.append(1)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466c9e47",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64f6961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_self_attention import SeqSelfAttention\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Permute, Dropout,Add,LSTM,Reshape,Bidirectional\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D,AveragePooling1D,GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import SpatialDropout2D\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv1D,Conv2D, Conv2DTranspose, BatchNormalization, LeakyReLU, Dense, Lambda, Reshape, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import mse\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.models import Sequential, save_model, load_model\n",
    "from tensorflow.keras.layers import Input, Conv1D,Conv2D, Conv2DTranspose, BatchNormalization, LeakyReLU, Dense, Lambda, Reshape, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import mse\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.preprocessing import minmax_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92023707",
   "metadata": {},
   "source": [
    "# feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6698c60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir('/home/jupy/SavedModel/autoencoder/T0_to_T0')\n",
    "#os.chdir('/home/jupy/SavedModel/autoencoder/T15_to_T15')\n",
    "mm_feature_output_0_0={}\n",
    "for n in range(0,60):#2-48\n",
    "    xar_0=XX_0[n*26:(n+1)*26,:,:]\n",
    "    xar_norm_0=np.zeros([xar_0.shape[0],xar_0.shape[1],xar_0.shape[2]])\n",
    "    for i in range(0,xar_0.shape[0]):\n",
    "        for j in range(0,xar_0.shape[1]):\n",
    "            xar_norm_0[i,j,:]=minmax_scale(xar_0[i,j,:])\n",
    "    xar_0=xar_norm_0\n",
    "    xar_0=np.expand_dims(xar_0,axis=-1)\n",
    "    mm=load_model(f'T0_to_T0_VAE{n}')\n",
    "\n",
    "    intermediate_layer_model = Model(inputs=mm.input,outputs=mm.get_layer('spatial_conv').output)\n",
    "    #intermediate_layer_model.compile(optimizer=Adam(learning_rate=0.001))\n",
    "    mm_feature_output_0_0[n]= intermediate_layer_model.predict(xar_0)\n",
    "    \n",
    "adapt_auto_feat_0_0=np.zeros([26*60,1,1217,8])\n",
    "for n in range(0,60):\n",
    "    adapt_auto_feat_0_0[n*26:(n+1)*26,:,:,:]=mm_feature_output_0_0[n]\n",
    "Adapt_feat_0_0=np.zeros([26*60,1217*8])\n",
    "for i in range(0,adapt_auto_feat_0_0.shape[0]):\n",
    "    Adapt_feat_0_0[i,:]=adapt_auto_feat_0_0[i,:,:,:].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904e37ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Adapt_feat_0_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405c6cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_0=np.zeros([XX_0.shape[0],(XX_0.shape[1]*XX_0.shape[2])])\n",
    "for i in range(0,1560):\n",
    "    raw_0[i,:]=XX_0[i,:,:].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc35004",
   "metadata": {},
   "source": [
    "### Convex Hull\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23e5307",
   "metadata": {},
   "source": [
    "# Genetic Algorithm"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6de77c33",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def objective(x):\n",
    "    good_q_id=np.where(np.array(hull_area)<=x[0])[0]\n",
    "    midhigh_q_id = np.where((x[0] < np.array(hull_area)) & (np.array(hull_area) <=x[1]))[0]\n",
    "    midlow_q_id = np.where((x[1] < np.array(hull_area)) & (np.array(hull_area) <= x[2]))[0]\n",
    "    bad_q_id = np.where(np.array(hull_area)>x[2])[0]\n",
    "    quality_y=np.empty([1560,])\n",
    "    \n",
    "    for i in good_q_id:\n",
    "        quality_y[np.arange(i*26,(i+1)*26)]=0\n",
    "    for j in midhigh_q_id:\n",
    "        quality_y[np.arange(j*26,(j+1)*26)]=1\n",
    "    for r in midlow_q_id:\n",
    "        quality_y[np.arange(r*26,(r+1)*26)]=1\n",
    "    for z in bad_q_id:\n",
    "        quality_y[np.arange(z*26,(z+1)*26)]=2\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Adapt_feat_0_0, quality_y, test_size=0.2, random_state=42,stratify=quality_y\n",
    "    )\n",
    "    rf.fit(X_train, y_train) # n_estimator=200\n",
    "    y_pred = rf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    #print(f\"Accuracy: {accuracy}\")\n",
    "    \n",
    "    return accuracy \n",
    "\n",
    "from numpy.random import randint\n",
    "from numpy.random import rand\n",
    "\n",
    "# decode bitstring to numbers\n",
    "def decode(bounds, n_bits, bitstring):\n",
    "\tdecoded = list()\n",
    "\tlargest = 2**n_bits\n",
    "\tfor i in range(len(bounds)):\n",
    "\t\t# extract the substring\n",
    "\t\tstart, end = i * n_bits, (i * n_bits)+n_bits\n",
    "\t\tsubstring = bitstring[start:end]\n",
    "\t\t# convert bitstring to a string of chars\n",
    "\t\tchars = ''.join([str(s) for s in substring])\n",
    "\t\t# convert string to integer\n",
    "\t\tinteger = int(chars, 2)\n",
    "\t\t# scale integer to desired range\n",
    "\t\tvalue = bounds[i][0] + (integer/largest) * (bounds[i][1] - bounds[i][0])\n",
    "\t\t# store\n",
    "\t\tdecoded.append(value)\n",
    "\treturn decoded\n",
    "\n",
    "# tournament selection\n",
    "def selection(pop, scores, k=3):\n",
    "\t# first random selection\n",
    "\tselection_ix = randint(len(pop))\n",
    "\tfor ix in randint(0, len(pop), k-1):\n",
    "\t\t# check if better (e.g. perform a tournament)\n",
    "\t\tif scores[ix] < scores[selection_ix]:\n",
    "\t\t\tselection_ix = ix\n",
    "\treturn pop[selection_ix]\n",
    "\n",
    "# crossover two parents to create two children\n",
    "def crossover(p1, p2, r_cross):\n",
    "\t# children are copies of parents by default\n",
    "\tc1, c2 = p1.copy(), p2.copy()\n",
    "\t# check for recombination\n",
    "\tif rand() < r_cross:\n",
    "\t\t# select crossover point that is not on the end of the string\n",
    "\t\tpt = randint(1, len(p1)-2)\n",
    "\t\t# perform crossover\n",
    "\t\tc1 = p1[:pt] + p2[pt:]\n",
    "\t\tc2 = p2[:pt] + p1[pt:]\n",
    "\treturn [c1, c2]\n",
    "\n",
    "# mutation operator\n",
    "def mutation(bitstring, r_mut):\n",
    "\tfor i in range(len(bitstring)):\n",
    "\t\t# check for a mutation\n",
    "\t\tif rand() < r_mut:\n",
    "\t\t\t# flip the bit\n",
    "\t\t\tbitstring[i] = 1 - bitstring[i]\n",
    "\n",
    "# genetic algorithm\n",
    "def genetic_algorithm(objective, bounds, n_bits, n_iter, n_pop, r_cross, r_mut):\n",
    "\t# initial population of random bitstring\n",
    "\tpop = [randint(0, 2, n_bits*len(bounds)).tolist() for _ in range(n_pop)]\n",
    "\t# keep track of best solution\n",
    "\tbest, best_eval = 0, objective(decode(bounds, n_bits, pop[0]))\n",
    "\t# enumerate generations\n",
    "\tfor gen in range(n_iter):\n",
    "\t\t# decode population\n",
    "\t\tdecoded = [decode(bounds, n_bits, p) for p in pop]\n",
    "\t\t# evaluate all candidates in the population\n",
    "\t\tscores = [objective(d) for d in decoded]\n",
    "\t\t# check for new best solution\n",
    "\t\tfor i in range(n_pop):\n",
    "\t\t\tif scores[i] < best_eval:\n",
    "\t\t\t\tbest, best_eval = pop[i], scores[i]\n",
    "\t\t\t\tprint(\">%d, new best f(%s) = %f\" % (gen,  decoded[i], scores[i]))\n",
    "\t\t# select parents\n",
    "\t\tselected = [selection(pop, scores) for _ in range(n_pop)]\n",
    "\t\t# create the next generation\n",
    "\t\tchildren = list()\n",
    "\t\tfor i in range(0, n_pop, 2):\n",
    "\t\t\t# get selected parents in pairs\n",
    "\t\t\tp1, p2 = selected[i], selected[i+1]\n",
    "\t\t\t# crossover and mutation\n",
    "\t\t\tfor c in crossover(p1, p2, r_cross):\n",
    "\t\t\t\t# mutation\n",
    "\t\t\t\tmutation(c, r_mut)\n",
    "\t\t\t\t# store for next generation\n",
    "\t\t\t\tchildren.append(c)\n",
    "\t\t# replace population\n",
    "\t\tpop = children\n",
    "\treturn [best, best_eval]\n",
    "\n",
    "# define range for input\n",
    "bounds = [[0, 150], [150, 250], [250, 350]]\n",
    "# define the total iterations\n",
    "n_iter = 100\n",
    "# bits per variable\n",
    "n_bits = 16\n",
    "# define the population size\n",
    "n_pop = 100\n",
    "# crossover rate\n",
    "r_cross = 0.9\n",
    "# mutation rate\n",
    "r_mut = 1.0 / (float(n_bits) * len(bounds))\n",
    "# perform the genetic algorithm search\n",
    "best, score = genetic_algorithm(objective, bounds, n_bits, n_iter, n_pop, r_cross, r_mut)\n",
    "print('Done!')\n",
    "decoded = decode(bounds, n_bits, best)\n",
    "print('f(%s) = %f' % (decoded, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886e08b6",
   "metadata": {},
   "source": [
    "0-125: good qulaity\n",
    "126-220:middle quality\n",
    "220-:bad quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e21f95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_y=[]\n",
    "for i in range(0,int(Adapt_feat_0_0.shape[0]/26)):\n",
    "     subj_y.append([i]*26)\n",
    "subj_y=np.array(subj_y).flatten()\n",
    "subj_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43fc114",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "n_estimators = 200\n",
    "rf = RandomForestClassifier(n_estimators=n_estimators, bootstrap=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(Adapt_feat_0_0, quality_y, test_size=0.2, random_state=42,stratify=quality_y\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "rf.feature_importances_\n",
    "feat_id=rf.feature_importances_.argsort()[-500:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceb1ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "581b0f40",
   "metadata": {},
   "source": [
    "# clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4817ad99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2) \n",
    "ardata=Adapt_feat_0_0\n",
    "tsardata=tsne.fit_transform(ardata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc39831",
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = []\n",
    "for k in range(1, 20):  # You can adjust the range of k as needed\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(tsardata)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the elbow curve\n",
    "plt.plot(range(1, 20), inertia, marker='o')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.xticks(range(1, 20))\n",
    "#plt.title('Elbow for Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2819007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "n_clusters = 5 # Number of clusters\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "kmeans.fit(ardata)\n",
    "cluster_assignments = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c243590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_assignments.shape\n",
    "cluster_purity=[]\n",
    "for i in range(0,60):\n",
    "    cluster_count=(np.unique(cluster_assignments[i*26:(i+1)*26], return_counts=True)[0].shape[0])\n",
    "    #print(np.unique(cluster_assignments[i*26:(i+1)*26], return_counts=True)[0].shape[0])\n",
    "    cluster_purity.append(cluster_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0684dc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, bins, _ = plt.hist(cluster_purity, bins=9)\n",
    "for count, x in zip(counts, bins):\n",
    "    if count > 0:  # Remove 0 count\n",
    "        plt.text(x + (bins[1] - bins[0]) / 2, count, str(int(count)), ha='center', va='bottom', fontsize=10, color='black')\n",
    "\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Number of Subjects')\n",
    "plt.xticks(range(1, 6))  # Set the x-axis to start from 1 to 9\n",
    "plt.yticks(range(0, 23, 5))  # Set the y-axis range from 0 to 22 with intervals of 5\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d537dbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "good_q_id=np.where(np.array(cluster_purity)<=2)[0]\n",
    "midhigh_q_id = np.where((2 < np.array(cluster_purity)) & (np.array(cluster_purity) <=3))[0]\n",
    "midlow_q_id = np.where((3< np.array(cluster_purity)) & (np.array(cluster_purity) <= 3.5))[0]\n",
    "bad_q_id = np.where(np.array(cluster_purity)>3.5)[0]\n",
    "\n",
    "print('good subj',good_q_id)\n",
    "print('midhigh subj',midhigh_q_id)\n",
    "print('midlow subj',midlow_q_id)\n",
    "print('bad subj',bad_q_id)\n",
    "\n",
    "quality_y=np.empty([1560,])\n",
    "#quality_ar=np.zeros[1560,9736]\n",
    "for i in good_q_id:\n",
    "    #print(np.arange(i*26,(i+1)*26))\n",
    "    quality_y[np.arange(i*26,(i+1)*26)]=0\n",
    "    \n",
    "for j in midhigh_q_id:\n",
    "    quality_y[np.arange(j*26,(j+1)*26)]=1\n",
    "    \n",
    "for r in midlow_q_id:\n",
    "    quality_y[np.arange(r*26,(r+1)*26)]=1\n",
    "    \n",
    "for z in bad_q_id:\n",
    "    quality_y[np.arange(z*26,(z+1)*26)]=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d081153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Number of trees in the Random Forest\n",
    "n_estimators = 200\n",
    "\n",
    "# Create a Random Forest classifier with bootstrapping\n",
    "rf = RandomForestClassifier(n_estimators=n_estimators, bootstrap=True)\n",
    "\n",
    "# Split your data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(Adapt_feat_0_0, quality_y, test_size=0.2, random_state=42,stratify=quality_y\n",
    ")#, \n",
    "# Train the Random Forest model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bde2982",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.feature_importances_\n",
    "feat_id=rf.feature_importances_.argsort()[-500:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35da7a61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72784463",
   "metadata": {},
   "source": [
    "# train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c14bba",
   "metadata": {},
   "source": [
    "Insert a token as subeject ID\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2cd45a0b",
   "metadata": {},
   "source": [
    "column_to_insert = subj_y\n",
    "# Number of columns in between each insertion\n",
    "insert_interval = 10\n",
    "# Initialize the modified array\n",
    "modified_array = np.copy(Adapt_feat_0_0)\n",
    "# Iterate through every 10 columns\n",
    "for i in range(0, modified_array.shape[1], insert_interval):\n",
    "    # Insert the column at the current position\n",
    "    modified_array = np.insert(modified_array, i, column_to_insert, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2362dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_range=range(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a943cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_ind=[]\n",
    "for n in range(0,10):\n",
    "    data_ind.append(np.array([30,31,32,0,1,2])+n*3)\n",
    "\n",
    "Xtest_id={}\n",
    "Xtv_id={}\n",
    "\n",
    "\n",
    "for s in s_range:    \n",
    "    Xtest_id[s]=data_ind[s]\n",
    "    #Xtv_id[s]=flatten(data_ind[0:s]+data_ind[(s+1):])\n",
    "    Xtv_id[s]=(np.array(data_ind[0:s]).flatten().tolist())+(np.array(data_ind[(s+1):]).flatten().tolist())\n",
    "    print('set',s,Xtest_id[s])\n",
    "    print('set',s,Xtv_id[s])\n",
    "    print('----------------------------')\n",
    "    \n",
    "Xdata= #raw_0#Adapt_feat_0_0#[:,feat_id]\n",
    "Ydata=np.array(Y2)#quality_y#\n",
    "Xtv={}\n",
    "Ytv={}\n",
    "Xtest={}\n",
    "Ytest={}\n",
    "for s in s_range:\n",
    "    print('set',s)\n",
    "    Xtest[s]=np.zeros([Xdata.shape[0],Xdata.shape[1]])\n",
    "    Ytest[s]=np.zeros([Xdata.shape[0],])\n",
    "    print('test_id',Xtest_id[s])\n",
    "    for test_id in Xtest_id[s]:\n",
    "            Xtest[s]=np.vstack([Xtest[s],Xdata[test_id*number_of_epochs:(test_id+1)*number_of_epochs,:]])\n",
    "            Ytest[s]=np.hstack([Ytest[s],Ydata[test_id*number_of_epochs:(test_id+1)*number_of_epochs,]])\n",
    "          \n",
    "    Xtest[s]=Xtest[s][Xdata.shape[0]:,:] \n",
    "    Ytest[s]=Ytest[s][Xdata.shape[0]:,] \n",
    "    \n",
    "    Xtv[s]=np.zeros([Xdata.shape[0],Xdata.shape[1]])\n",
    "    Ytv[s]=np.zeros([Xdata.shape[0],])\n",
    "    print('tv_id',Xtv_id[s])\n",
    "    for tv_id in Xtv_id[s]:\n",
    "            Xtv[s]=np.vstack([Xtv[s],Xdata[tv_id*number_of_epochs:(tv_id+1)*number_of_epochs,:]])\n",
    "            Ytv[s]=np.hstack([Ytv[s],Ydata[tv_id*number_of_epochs:(tv_id+1)*number_of_epochs,]])\n",
    "            \n",
    "    Xtv[s]=Xtv[s][Xdata.shape[0]:,:] \n",
    "    Ytv[s]=Ytv[s][Xdata.shape[0]:,] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81435c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xtv[s].shape, Ytv[s].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f63ac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_id_long={}\n",
    "X_all_shuffled={}\n",
    "Y_all_shuffled={}\n",
    "Y_all_shuffled_cat={}\n",
    "for s in s_range:\n",
    "    np.random.seed(2)\n",
    "    all_id_long[s]=np.arange(0,Xtv[s].shape[0])\n",
    "    np.random.shuffle(all_id_long[s])\n",
    "    \n",
    "    X_all_shuffled[s]=np.zeros([ Xtv[s].shape[0], Xtv[s].shape[1]])\n",
    "    Y_all_shuffled[s]=np.zeros([ Xtv[s].shape[0]])\n",
    "    for n in range(0,all_id_long[s].shape[0]):\n",
    "        X_all_shuffled[s][n,:]=Xtv[s][all_id_long[s][n],:]\n",
    "        #print(n,all_id_long[s][n])\n",
    "        Y_all_shuffled[s][n]=Ytv[s][all_id_long[s][n]]\n",
    "    print(X_all_shuffled[s].shape)\n",
    "    print(Y_all_shuffled[s].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc84101",
   "metadata": {},
   "source": [
    "accuracy of subject filtered feautres vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47cc144",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=[]\n",
    "for s in s_range:\n",
    "    knn.fit(X_all_shuffled[s],Y_all_shuffled[s])\n",
    "    print(accuracy_score(knn.predict(Xtest[s]),Ytest[s]))\n",
    "    scores.append(accuracy_score(knn.predict(Xtest[s]),Ytest[s]))\n",
    "print('avg',sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a50667",
   "metadata": {},
   "source": [
    "accuracy of vae as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854acaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=[]\n",
    "for s in s_range:\n",
    "    knn.fit(X_all_shuffled[s],Y_all_shuffled[s])\n",
    "    print(accuracy_score(knn.predict(Xtest[s]),Ytest[s]))\n",
    "    scores.append(accuracy_score(knn.predict(Xtest[s]),Ytest[s]))\n",
    "print('avg',sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e786a506",
   "metadata": {},
   "source": [
    "accuracy of raw eeg as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32197e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=[]\n",
    "for s in s_range:\n",
    "    knn.fit(X_all_shuffled[s],Y_all_shuffled[s])\n",
    "    print(accuracy_score(knn.predict(Xtest[s]),Ytest[s]))\n",
    "    scores.append(accuracy_score(knn.predict(Xtest[s]),Ytest[s]))\n",
    "print('avg',sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926de7ed",
   "metadata": {},
   "source": [
    "# 1D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8490c3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OneD_EEGNet(nb_classes=2,dropoutRate = 0.25,norm_rate = 0.25, dropoutType = 'Dropout'):\n",
    "\n",
    "        input1   = Input(shape = (9736, 1))\n",
    "\n",
    "        ##################################################################\n",
    "        block1       = Conv1D(8, (64))(input1)\n",
    "        block1       = BatchNormalization()(block1)\n",
    "        block1       = Activation('relu')(block1)\n",
    "\n",
    "        block1       = Conv1D(16, (32))(block1)\n",
    "        block1       = BatchNormalization()(block1)\n",
    "        block1       = Activation('relu')(block1)\n",
    "\n",
    "        block1       = AveragePooling1D((4))(block1)\n",
    "        block1       = Dropout(dropoutRate)(block1)\n",
    "\n",
    "        block2       = Conv1D(32, (16))(block1)\n",
    "        block2       = BatchNormalization()(block2)\n",
    "        block2       = Activation('relu')(block2)\n",
    "\n",
    "        block2       = AveragePooling1D((8))(block2)\n",
    "        #block2       = tf.keras.layers.GlobalAveragePooling2D()(block2)\n",
    "        block2       = Dropout(dropoutRate)(block2)\n",
    "\n",
    "        flatten      = Flatten(name = 'flatten')(block2)\n",
    "        initializer = initializer = tf.keras.initializers.Identity()\n",
    "        dense        = Dense(nb_classes, name = 'dense', \n",
    "                             kernel_constraint = max_norm(norm_rate),kernel_initializer=initializer)(flatten)\n",
    "        softmax      = Activation('softmax', name = 'softmax')(dense)\n",
    "\n",
    "        return Model(inputs=input1, outputs=softmax)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780b5630",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0fbd64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " for s in range(0,10):\n",
    "        \n",
    "    lr=tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=0.0005, decay_steps=50, decay_rate=0.9, staircase=False, name=None\n",
    "    )\n",
    "    adam=tf.keras.optimizers.Adam(learning_rate=0.001)#learning_rate=0.0005\n",
    "    \n",
    "    model=OneD_EEGNet()\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer =adam,metrics=['accuracy']) # optimizer = 'adam'\n",
    "    callback=tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20,restore_best_weights = True)\n",
    "    history=model.fit( X_all_shuffled[s].reshape(1404, 9736,1),\n",
    "                          to_categorical(Y_all_shuffled[s]),epochs=100, batch_size=100, validation_split=0.2, callbacks=[callback],verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5c7472",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights = model.get_weights()\n",
    "model.set_weights(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c33de7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_model=model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff18d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba43e98d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9f32a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir('/home/jupy/SavedModel/autoencoder/T0_to_T0/classifier')\n",
    "for s in range(0,10):\n",
    "    #classifier=load_model(f'n_set{s}_btw_encoder_T0_classifier')\n",
    "    classifier=model\n",
    "    result=[]\n",
    "    predicted=classifier.predict(Xtest[s])\n",
    "    for i in range (0,np.array(predicted).shape[0]):\n",
    "            if predicted[i][0]>predicted[i][1]:\n",
    "                result.append([0])\n",
    "            else:\n",
    "                result.append([1])\n",
    "    print('ep score',accuracy_score(result,Ytest[s]))\n",
    "    pred=subj_class_prob(result)\n",
    "\n",
    "    print('score',accuracy_score(pred,y_test_short))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f14bc0c",
   "metadata": {},
   "source": [
    "robust_layer_model = Model(inputs=quality_model.input,outputs=quality_model.get_layer('average_pooling1d_11').output)\n",
    "robust_feature_output= robust_layer_model.predict( X_all_shuffled[s])\n",
    "print(robust_feature_output.shape)\n",
    "robust_feature_output.shape\n",
    "robust_feature_outputs=np.zeros([1404,int(robust_feature_output.shape[1]*robust_feature_output.shape[2])])\n",
    "for i in range(0,1404):\n",
    "    robust_feature_outputs[i,:]=robust_feature_output[i,:,:].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70af5fec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03d6124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne= TSNE(n_components=2, perplexity=15)\n",
    "tsne_feat=tsne.fit_transform(Adapt_feat_0_0[:,feat_id])\n",
    "tsne_vae=tsne.fit_transform(Adapt_feat_0_0)\n",
    "tsne_org=tsne.fit_transform(raw_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cf325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in [0, 10, 20, 29, 31, 40, 48, 59]:\n",
    "    if i < 30:\n",
    "        plt.scatter(\n",
    "            tsne_org[i * 26:(i + 1) * 26, 0],\n",
    "            tsne_org[i * 26:(i + 1) * 26, 1],\n",
    "            alpha=0.7, marker='+',\n",
    "            s=50, label='Lean')\n",
    "    else:\n",
    "        plt.scatter(\n",
    "            tsne_org[i * 26:(i + 1) * 26, 0],\n",
    "            tsne_org[i * 26:(i + 1) * 26, 1],\n",
    "            alpha=0.5, marker='o',\n",
    "            s=50, label='Obese')\n",
    "\n",
    "#plt.legend(['Lean', 'Obese'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb362424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a0b1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [8, 4, 12, 24, 41, 49, 34, 50]:\n",
    "    if i < 30:\n",
    "        plt.scatter(\n",
    "            tsne_vae[i * 26:(i + 1) * 26, 0],\n",
    "            tsne_vae[i * 26:(i + 1) * 26, 1],\n",
    "            alpha=0.7, marker='+',\n",
    "            s=50, label='Lean')\n",
    "    else:\n",
    "        plt.scatter(\n",
    "            tsne_vae[i * 26:(i + 1) * 26, 0],\n",
    "            tsne_vae[i * 26:(i + 1) * 26, 1],\n",
    "            alpha=0.5, marker='o',\n",
    "            s=50, label='Obese')\n",
    "\n",
    "#plt.legend(['Lean', 'Obese'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb2fcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in [0, 10, 20, 29, 31, 40, 48, 59]:\n",
    "    if i < 30:\n",
    "        plt.scatter(\n",
    "            tsne_feat[i * 26:(i + 1) * 26, 0],\n",
    "            tsne_feat[i * 26:(i + 1) * 26, 1],\n",
    "            alpha=0.7, marker='+',\n",
    "            s=50, label='Lean')\n",
    "    else:\n",
    "        plt.scatter(\n",
    "            tsne_feat[i * 26:(i + 1) * 26, 0],\n",
    "            tsne_feat[i * 26:(i + 1) * 26, 1],\n",
    "            alpha=0.5, marker='o',\n",
    "            s=50, label='Obese')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34274bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cab58a1",
   "metadata": {},
   "source": [
    "# robust_feature_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bb5598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OneD_EEGNet(nb_classes=2,dropoutRate = 0.25,norm_rate = 0.25, dropoutType = 'Dropout'):\n",
    "\n",
    "        input1   = Input(shape = (9568, 1))\n",
    "\n",
    "        ##################################################################\n",
    "        block1       = Conv1D(8, (64))(input1)\n",
    "        block1       = BatchNormalization()(block1)\n",
    "        block1       = Activation('relu')(block1)\n",
    "\n",
    "        block1       = Conv1D(16, (32))(block1)\n",
    "        block1       = BatchNormalization()(block1)\n",
    "        block1       = Activation('relu')(block1)\n",
    "\n",
    "        block1       = AveragePooling1D((4))(block1)\n",
    "        block1       = Dropout(dropoutRate)(block1)\n",
    "\n",
    "        block2       = Conv1D(32, (16))(block1)\n",
    "        block2       = BatchNormalization()(block2)\n",
    "        block2       = Activation('relu')(block2)\n",
    "\n",
    "        block2       = AveragePooling1D((8))(block2)\n",
    "        #block2       = tf.keras.layers.GlobalAveragePooling2D()(block2)\n",
    "        block2       = Dropout(dropoutRate)(block2)\n",
    "\n",
    "        flatten      = Flatten(name = 'flatten')(block2)\n",
    "        initializer = initializer = tf.keras.initializers.Identity()\n",
    "        dense        = Dense(nb_classes, name = 'dense', \n",
    "                             kernel_constraint = max_norm(norm_rate),kernel_initializer=initializer)(flatten)\n",
    "        softmax      = Activation('softmax', name = 'softmax')(dense)\n",
    "\n",
    "        return Model(inputs=input1, outputs=softmax)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf67587",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " for s in range(0,10):\n",
    "        \n",
    "    lr=tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=0.001, decay_steps=50, decay_rate=0.9, staircase=False, name=None\n",
    "    )\n",
    "    adam=tf.keras.optimizers.Adam(learning_rate=0.0001)#learning_rate=0.0005\n",
    "    \n",
    "    model=OneD_EEGNet()\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer =adam,metrics=['accuracy']) # optimizer = 'adam'\n",
    "    callback=tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20,restore_best_weights = True)\n",
    "    history=model.fit( robust_feature_outputs.reshape(1404, 9568,1),\n",
    "                          to_categorical(Y_all_shuffled[s]),epochs=100, batch_size=100, validation_split=0.2, callbacks=[callback],verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1da074",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights = model.get_weights()\n",
    "model.set_weights(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcc73e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#robust_layer_model = Model(inputs=quality_model.input,outputs=quality_model.get_layer('average_pooling1d_1').output)\n",
    "robust_feature_output_test= robust_layer_model.predict( Xtest[s])\n",
    "\n",
    "\n",
    "robust_feature_outputs_test=np.zeros([Xtest[s].shape[0],int(299*32)])\n",
    "for i in range(0,Xtest[s].shape[0]):\n",
    "    robust_feature_outputs_test[i*26:(i+1)*26,:]=robust_feature_output_test[i,:,:].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fd9244",
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_feature_outputs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b0205e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()\n",
    "Xtest[s].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929b1301",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in range(0,10):\n",
    "    #classifier=load_model(f'n_set{s}_btw_encoder_T0_classifier')\n",
    "    classifier=model\n",
    "    result=[]\n",
    "    predicted=classifier.predict(robust_feature_outputs_test)\n",
    "    for i in range (0,np.array(predicted).shape[0]):\n",
    "            if predicted[i][0]>predicted[i][1]:\n",
    "                result.append([0])\n",
    "            else:\n",
    "                result.append([1])\n",
    "    print('ep score',accuracy_score(result,Ytest[s]))\n",
    "    pred=subj_class_prob(result)\n",
    "\n",
    "    print('score',accuracy_score(pred,y_test_short))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_py39",
   "language": "python",
   "name": "venv_py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
